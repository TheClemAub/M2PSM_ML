{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oSdjGwVWGshH"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import logging\n","logger = tf.get_logger()\n","logger.setLevel(logging.ERROR)\n","\n","_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n","zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)\n","zip_dir_base = os.path.dirname(zip_dir)\n","!find $zip_dir_base -type d -print\n","\n","base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'validation')\n","\n","train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n","train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n","validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n","\n","num_cats_tr = len(os.listdir(train_cats_dir))\n","num_dogs_tr = len(os.listdir(train_dogs_dir))\n","\n","num_cats_val = len(os.listdir(validation_cats_dir))\n","num_dogs_val = len(os.listdir(validation_dogs_dir))\n","\n","total_train = num_cats_tr + num_dogs_tr\n","total_val = num_cats_val + num_dogs_val\n","\n","print('total training cat images:', num_cats_tr)\n","print('total training dog images:', num_dogs_tr)\n","print('total validation cat images:', num_cats_val)\n","print('total validation dog images:', num_dogs_val)\n","print(\"--\")\n","print(\"Total training images:\", total_train)\n","print(\"Total validation images:\", total_val)\n","\n","BATCH_SIZE = 100\n","IMG_SHAPE  = 150\n","train_image_generator      = ImageDataGenerator(rescale=1./255)\n","validation_image_generator = ImageDataGenerator(rescale=1./255)\n","\n","train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n","                                                           directory=train_dir,\n","                                                           shuffle=True,\n","                                                           target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n","                                                           class_mode='binary')\n","val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n","                                                              directory=validation_dir,\n","                                                              shuffle=False,\n","                                                              target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n","                                                              class_mode='binary')\n","sample_training_images, _ = next(train_data_gen)\n","def plotImages(images_arr):\n","    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n","    axes = axes.flatten()\n","    for img, ax in zip(images_arr, axes):\n","        ax.imshow(img)\n","    plt.tight_layout()\n","    plt.show()\n","\n","plotImages(sample_training_images[:5])\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(2)\n","])\n","\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","model.summary()\n","\n","for data_batch, labels_batch in train_data_gen:\n","    print('data batch shape:', data_batch.shape)\n","    print('labels batch shape:', labels_batch.shape)\n","    break\n","\n","for data_batch, labels_batch in val_data_gen:\n","    print('data batch shape:', data_batch.shape)\n","    print('labels batch shape:', labels_batch.shape)\n","    break\n","\n","EPOCHS = 10\n","history = model.fit(\n","    train_data_gen,\n","    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n","    epochs=EPOCHS,\n","    validation_data=val_data_gen,\n","    validation_steps=None,\n","    verbose=1\n",")\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(EPOCHS)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.savefig('./foo.png')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[{"file_id":"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l05c01_dogs_vs_cats_without_augmentation.ipynb","timestamp":1726156912308}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}